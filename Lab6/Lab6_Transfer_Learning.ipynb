{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    
    "colab": {
      "name": "Lab6-Transfer-Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXelAlZrGs0o",
        "colab_type": "text"
      },
      "source": [
        "#Сверточные нейронные сети (Convolutional Neural Network, CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpNGKmcJG27x",
        "colab_type": "text"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UdI3DDOHvLZ",
        "colab_type": "text"
      },
      "source": [
        "Сверточные сети построены на операции свертки.\n",
        "\n",
        "Имеется ядро – небольшая матрица весов. Это ядро «скользит» по двумерным входным данным, выполняя поэлементное умножение для той части данных, которую сейчас покрывает. Результаты перемножений ячеек суммируются в одном выходном пикселе. В случае сверточных нейросетей ядро определяется в ходе обучения сети. \n",
        "\n",
        "Перемножение и суммирование повторяются для каждой локации, по которой проходит ядро. Двумерная матрица входных признаков преобразуется в двумерную матрицу выходных. Выходные признаки, таким образом, являются взвешенными суммами входных признаков. Число входных признаков в комбинации для одного выходного признака определяет размер ядра."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhxYG9QR2EqL",
        "colab_type": "text"
      },
      "source": [
        "![convUrl](https://media.proglib.io/wp-uploads/2018/06/2.gif \"Convolution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WffTQbEm2ZU7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Если представить находящуюся выше матрицу 5х5 как картинку: матрицу интенсивности пикселей, где 0 это черный, а 3 это белый, а 1 и 2 темно-серый и светло-серый, то получим некоторую картинку, к которой применяем нашу свертку - квадрат 3х3. На данной картинке это квадрат со значениями 0,1,2,2,2,0,0,1,2. Применяем свертку, то есть перемножаем ячейки свертки и картинки. Например, для первой ячейки выходной матрицы:\n",
        "\n",
        "\n",
        "$3*0+3*1+2*2+0*2+0*2+1*0+3*0+1*1+2*2=12$\n",
        "\n",
        "В целом, мы подаем на вход картинку, а получаем на выходе рассчитанные по ней коэффициенты."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw2K1BACsVGb",
        "colab_type": "text"
      },
      "source": [
        "# Многоканальность"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELbnCvKxsf02",
        "colab_type": "text"
      },
      "source": [
        "Если раньше мы работали с черно-белыми изображениями, то в этот раз изображения цветные. Поэтому вместо одного канала мы теперь имеем три - по числу цветов RGB модели. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHQIBdXDtZgj",
        "colab_type": "text"
      },
      "source": [
        "![channelsUrl](https://neurohive.io/wp-content/uploads/2018/07/rgb-svertochnaja-neiroset.gif \"Сhannels\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7Tq2ULLtxWf",
        "colab_type": "text"
      },
      "source": [
        "Свертка проходит по каждому из каналов, а затем суммирует их."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOSTXr6Btljn",
        "colab_type": "text"
      },
      "source": [
        "![channelsSumUrl](https://neurohive.io/wp-content/uploads/2018/07/glubokaja-svertochnaja-neironnaja-set.gif \"Сhannels_Sum\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXzk_MMkt0ll",
        "colab_type": "text"
      },
      "source": [
        "Таким образом,  нейронная сеть будет принимать на вход изображения размером nxn и 3 канала. Например, (150,150,3), как в нашей сети."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws06a1MgsGEi",
        "colab_type": "text"
      },
      "source": [
        "# Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiqsKS2hsLoy",
        "colab_type": "text"
      },
      "source": [
        "Еще один специальный слой, явяющийся подвыборочным. Он используется с целью уменьшения размерности предыдущего слоя. Если на предыдущей операции свертки уже были выявлены некоторые признаки, то для дальнейшей обработки настолько подробное изображение уже не нужно, и оно уплотняется до менее подробного. К тому же фильтрация уже ненужных деталей помогает не переобучаться.\n",
        "\n",
        "Чаще всего используется уменьшение изображения в два раза путем использования матрицы 2х2 через операцию взятия максимума."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ozs7uuJwY15",
        "colab_type": "text"
      },
      "source": [
        "# Теперь поговорим о предобученных сетях"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHHpP_7NwgTV",
        "colab_type": "text"
      },
      "source": [
        "Обучение нейронной сети занимает не только много времени, но и требует большой размеченной выборки. Конечно, можно создавать свои сети с нуля и подбирать сеть для каждого конкретного случая. А можно упростить себе жизнь и взять для нашей задачи уже готовую нейронную сеть, обученную в течение долгого времени и показавшую хорошие результаты на своей задаче. Такая техника называется Transfer Learning или Перенос обучения.\n",
        "\n",
        "То есть, Transfer Learning - это процесс дообучения на новых данных какой-либо нейросети, уже обученной до этого на других данных, обычно на каком-нибудь хорошем, большом (миллионы картинок) датасете.\n",
        "\n",
        "Например, у нас есть сеть, хорошо распознающая самолет на картинке или танк. А мы хотим применить ее для распознавания кошек и собак. Так как на первых слоях нейронной сети происходит общая оценка изображения и мы не успеваем дойти до специфичных признаков, мы можем использовать такую сеть для распознавания котов и собак.\n",
        "\n",
        "Есть три основных пути:\n",
        "* Взять предобученную на других данных нейронную сеть и просто предсказать наши картинки:\n",
        "\n",
        " +Не надо тратить время на обучение\n",
        "\n",
        " -Точность будет низкая для нашей задачи, если она сильно отличается\n",
        "\n",
        "* Взять предобученную на других данных нейронную сеть, добавить к ней новые слои и обучить только их\n",
        "\n",
        " +Сокращается время на обучение, происходит подгон под нашу задачу\n",
        "\n",
        " -Точность будет выше, однако добавление новых слоев может перегрузить сеть\n",
        "\n",
        "* Взять предобученную на других данных нейронную сеть, добавить новые слои. Но вместе с тем обучить не только новые слои, но и часть предобученной сети. Этот метод носит название Fine Tuning или Тонкая настройка.\n",
        "\n",
        " +Обучается не вся сеть, а только часть, отвечающая за специфичные признаки изображения\n",
        "\n",
        " -Точность должна возрасти, однако вероятно переобучение\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKHzuWHG0evx",
        "colab_type": "text"
      },
      "source": [
        "В зависимости от количества и природы Ваших данных есть выбор из нескольких стратегий Transfer Learning, а именно:\n",
        "\n",
        "* *У Вас **мало данных** ($\\le$ 10k), и они **похожи** на данные, на которых была обучена сеть до этого*  \n",
        "\n",
        "Можно использовать просто готовую модель. Но если точность вышла низкая, можно использовать второй путь. Если применить Fine-Tuning (3 способ), то сеть может переобучиться, поскольку данных мало.\n",
        "* *У Вас **мало данных** ($\\le$ 10k), и они **не похожи** на данные, на которых была обучена сеть до этого*  \n",
        "\n",
        "Самый плохой вариант. Хорошим выходом будет второй вариант, но возможно придется выкинуть часть последних слоев преобученной сети и тогда уже добавить свой.\n",
        "* *У Вас **много данных** ($\\ge$ 10k), и они **похожи** на данные, на которых была обучена сеть до этого*  \n",
        "\n",
        "Fine Tuning здесь подходит больше всего.\n",
        "* *У Вас **много данных** ($\\ge$ 10k), и они **не похожи** на данные, на которых была обучена сеть до этого*\n",
        "\n",
        "Обычно здесь оставляют архитектуру сети и используют запомненные веса как начальные. А потом заново обучают всю сеть."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKVOY5WT29xU",
        "colab_type": "text"
      },
      "source": [
        "Нашей стратегией в этой работе будет первый вариант."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSO4NFDLZhDF",
        "colab_type": "text"
      },
      "source": [
        "# Предобученная сеть VGG-16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiBRxnlMxgT8",
        "colab_type": "text"
      },
      "source": [
        "VGG-16 — модель сверточной нейронной сети, предложенная K. Simonyan и A. Zisserman из Оксфордского университета в статье “Very Deep Convolutional Networks for Large-Scale Image Recognition”. Модель достигает точности 92.7% — топ-5, при тестировании ImageNet в задаче распознавания объектов на изображении. Этот датасет состоит из более чем 14 миллионов изображений, принадлежащих к 1000 классам."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGivCyLzaslA",
        "colab_type": "text"
      },
      "source": [
        "Архитектуру данной сети вы можете увидеть на картинке.\n",
        "\n",
        "На момент создания VGG люди уже заметили, что чем больше слоев в нейросети, тем выше ее точность. Заменяя большие фильтры на несколько фильтров 3$\\times$3 исследователи получили глубокую нейросеть с меньшим количеством параметров. Архитектура VGG-16 (версии VGG с 16 слоями) представлена на картинке ниже:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXXirCVqaslE",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://cdn-images-1.medium.com/max/1040/1*0Tk4JclhGOCR_uLe6RKvUQ.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyiBl5hsaslJ",
        "colab_type": "text"
      },
      "source": [
        "Когда говорят VGG, то чаще всего имеют ввиду VGG-16 или VGG-19. Более глубоких версий VGG нет, так как после 19 слоев точность начинает падать."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRWqz65kGz1H",
        "colab_type": "text"
      },
      "source": [
        "#Основные шаги по выполнению лабораторной работы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BNBKwW8d7Ik",
        "colab_type": "text"
      },
      "source": [
        "##Подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36v49-4elSNS",
        "colab_type": "text"
      },
      "source": [
        "Для начала работы подготовим данные"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBHKF8dWeCbB",
        "colab_type": "text"
      },
      "source": [
        "Скачайте файл train.zip с набором изображений кошек и собак с сайта соревнования Kaggle [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/data) и распакуйте его. Создайте папку cat_dogs (нажиамем правой кнопкой где-нибудь в поле, где находится sample_data, нажимаем new folder) и сделайте upload для 500 снимков кошек (cat0.jpg-cat499.jpg) и 500 собак (dog0.jpg-dog499.jpg). \n",
        "\n",
        "Чем на большем объеме данных будет обучаться ваша сеть, тем лучше, но это так же сильно увеличит время обучения сети. В реальных задачах это нормально, если  обучение нейронной сети на большом объеме данных занимает более 12 часов.  При обучении на всех изображениях точность продемонстрированных ниже сетей будет достигать 97%.\n",
        "\n",
        "В рамках данной работы мы возьмем только 500 изображений, для экономии учебного времени."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu4nR89RlT75",
        "colab_type": "text"
      },
      "source": [
        "Распределим эти фотографии по папкам: train, test и val. \n",
        "\n",
        "Каждая папка будет содержать две подпапки: cats и dogs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfqGmdHydEde",
        "colab_type": "code",
        "outputId": "6885cd3e-b011-4b17-8f32-afd7c856144c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WlMsw3Zd_I-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5A2gTOfeO7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Каталог с набором данных\n",
        "data_dir = './cat_dogs/'\n",
        "# Каталог с данными для обучения\n",
        "train_dir = 'train'\n",
        "# Каталог с данными для проверки\n",
        "val_dir = 'val'\n",
        "# Каталог с данными для тестирования\n",
        "test_dir = 'test'\n",
        "# Часть набора данных для тестирования\n",
        "test_data_portion = 0.15\n",
        "# Часть набора данных для проверки\n",
        "val_data_portion = 0.15\n",
        "# Количество элементов данных в одном классе\n",
        "nb_images = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCdpOq3Qlu6a",
        "colab_type": "text"
      },
      "source": [
        "Функция создания каталога с двумя подкаталогами по названию классов: cats и dogs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aO_T8vYky5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_directory(dir_name):\n",
        "    if os.path.exists(dir_name):\n",
        "        shutil.rmtree(dir_name)\n",
        "    os.makedirs(dir_name)\n",
        "    os.makedirs(os.path.join(dir_name, \"cats\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"dogs\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmcuPGK8lymp",
        "colab_type": "text"
      },
      "source": [
        "Создание структуры каталогов для обучающего, проверочного и тестового набора данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr3fie4uk3Au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_directory(train_dir)\n",
        "create_directory(val_dir)\n",
        "create_directory(test_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xUwnLmCl0uA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Функция копирования изображений в заданный каталог. Изображения котов и собак копируются в отдельные подкаталоги"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paGtIfMCk-Dk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def copy_images(start_index, end_index, source_dir, dest_dir):\n",
        "    for i in range(start_index, end_index):\n",
        "        shutil.copy2(os.path.join(source_dir, \"cat.\" + str(i) + \".jpg\"), \n",
        "                    os.path.join(dest_dir, \"cats\"))\n",
        "        shutil.copy2(os.path.join(source_dir, \"dog.\" + str(i) + \".jpg\"), \n",
        "                   os.path.join(dest_dir, \"dogs\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSgB_lVGl297",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Расчет индексов наборов данных для обучения, проверки и тестирования"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clDnZ7i3lAAY",
        "colab_type": "code",
        "outputId": "3149fd88-e5be-4505-de03-ac36b534b5f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "start_val_data_idx = int(nb_images * (1 - val_data_portion - test_data_portion))\n",
        "start_test_data_idx = int(nb_images * (1 - test_data_portion))\n",
        "print(start_val_data_idx)\n",
        "print(start_test_data_idx)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "350\n",
            "425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5A2Ks-AmHDr",
        "colab_type": "text"
      },
      "source": [
        "Копирование изображений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I1T0i57lCUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "copy_images(0, start_val_data_idx, data_dir, train_dir)\n",
        "copy_images(start_val_data_idx, start_test_data_idx, data_dir, val_dir)\n",
        "copy_images(start_test_data_idx, nb_images, data_dir, test_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDZMkIv4mDBB",
        "colab_type": "text"
      },
      "source": [
        "## Создание нейронной сети на базе предварительно обученной нейронной сети VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fijrMm_43PNg",
        "colab_type": "text"
      },
      "source": [
        "Сеть VGG16 ранее обучалась на похожих изображениях. Поэтому мы попробуем два способа:\n",
        "* добавим свои слои к сети VGG16, но саму сеть обучать не будем\n",
        "* разморозим только последний слой сети VGG16 и обучим с новыми слоями"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVuVnIXmmYO_",
        "colab_type": "text"
      },
      "source": [
        "### Импортируем необходимые библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of2jctaTlFst",
        "colab_type": "code",
        "outputId": "ea8ec8c4-cd71-44b8-b165-189296393b69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.models import Sequential, Model\n",
        "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.python.keras.applications import VGG16\n",
        "from tensorflow.python.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCRdvqBEmnL5",
        "colab_type": "text"
      },
      "source": [
        "Определим оставшиеся константы:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRVEMD9mmqt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Размеры изображения\n",
        "img_width, img_height = 150, 150\n",
        "# Размерность тензора на основе изображения для входных данных в нейронную сеть\n",
        "input_shape = (img_width, img_height, 3)\n",
        "# Размер мини-выборки\n",
        "batch_size = 64\n",
        "# Количество изображений для обучения\n",
        "nb_train_samples = 700\n",
        "# Количество изображений для проверки\n",
        "nb_validation_samples = 150\n",
        "# Количество изображений для тестирования\n",
        "nb_test_samples = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1A1H5k3pmQk",
        "colab_type": "text"
      },
      "source": [
        "Следующей строчкой мы загрузим предварительно обученную сеть VGG16. Сразу установим входную размерность, а именно 150 пикселей ширины на 150 пикселей выосоты на 3 канала цвета."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULsV6Ua9paeh",
        "colab_type": "code",
        "outputId": "5d7d8f5f-ba69-4de8-823b-88bd5d95d36f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "vgg16_net = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syeEUTWdpv3V",
        "colab_type": "text"
      },
      "source": [
        "\"Замораживаем\" веса предварительно обученной нейронной сети VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OyKAKsvp1CA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_net.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4BfTGV7p4hT",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим на структуру загруженной сети."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-kFTd-Vp2ZH",
        "colab_type": "code",
        "outputId": "c021cf3f-f4f0-4bd7-c160-9cb68e88fd56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "source": [
        "vgg16_net.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQeY63qWp-Lq",
        "colab_type": "text"
      },
      "source": [
        "Теперь давайте добавим к имеющейся сети несколько новых слоев. Возьмем выходные данные VGG16 нейронной сети и подадим их на вход нашего нового слоя Flatten, который преобразует эти данные в одномерный вектор. \n",
        "\n",
        "Dense - это уже знакомый нам полносвязный слой. \n",
        "\n",
        "Дальше идет слой Dropout, который \"исключает\" заданный процент нейронов. “Исключение” нейрона означает, что при любых входных данных или параметрах он возвращает 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYK_n8BSp3-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = vgg16_net.output\n",
        "x = Flatten(name=\"flatten\")(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = Model(inputs=vgg16_net.input, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLEW79IvrTMB",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим на структуру получившейся составной сети. Мы можем увидеть новые слои в конце."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm5oylmHrSt0",
        "colab_type": "code",
        "outputId": "87ea5767-a4fc-460b-84bd-99fedd5f9da9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 16,812,353\n",
            "Trainable params: 2,097,665\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pam3-x0ErZ2n",
        "colab_type": "code",
        "outputId": "49c367d9-768e-4935-fd55-154728080cc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zy3cvLfsC3c",
        "colab_type": "text"
      },
      "source": [
        "### Создаем генератор изображений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT8hvopFpUBG",
        "colab_type": "text"
      },
      "source": [
        "Еще один способ подать данные в сеть - это с помощью генератора изображений. Процесс предподготовки данных (например,оптимальное разбитие на выборки, нормализация или изменения размера изображения) имеет большое значение для нейронных сетей. Некоторые из этих процессов можно прописывать отдельно, а можно применить генератор изображений. \n",
        "\n",
        "В данном случае мы сделаем несколько вещей при помощи генератора:\n",
        "* Нормализуем данные\n",
        "* Изменим размерность картинок на подходящий в нейронную сеть\n",
        "* Пропишем размер мини-выборки\n",
        "\n",
        "Мы уже сталкивались с данными, в которых представителей одного класса больше, чем других. В таком случае часто применяется искуственная генерация изображений. Например, путем поворота или отражения картинки, увеличения или уменьшения, размытия четкоси. Все это позволяет делать генератор изображений, однако в данной работы мы не будем останавливаться на этом. Используем генератор для описанных выше целей.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ-vB0oNsT7R",
        "colab_type": "text"
      },
      "source": [
        "Итак, генератор изображений создается на основе класса ImageDataGenerator. Генератор делит значения всех пикселов изображения на 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZci8neOrojf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3QkgZRysX8n",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Генератор данных для обучения, проверки и тестирования на основе изображений из каталога"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B3_JBn3sIBx",
        "colab_type": "code",
        "outputId": "63ba2cdf-d962-4891-92c7-1e2583e202ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 700 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RJ-H3c7sJVu",
        "colab_type": "code",
        "outputId": "9be162e3-a41c-409b-922f-98b9a9002683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 150 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVRDyRIqsLTh",
        "colab_type": "code",
        "outputId": "8455f18d-ae66-44c5-89b0-0c52222e42bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 150 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbSvJo2LsgDh",
        "colab_type": "text"
      },
      "source": [
        "### Обучаем модель с использованием генераторов\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAIVYY9esNE3",
        "colab_type": "code",
        "outputId": "d108527e-1a12-4935-a3c0-ba2f5e94b745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.8842 - acc: 0.4931Epoch 1/10\n",
            "10/10 [==============================] - 172s 17s/step - loss: 0.8577 - acc: 0.5142 - val_loss: 0.7386 - val_acc: 0.4688\n",
            "Epoch 2/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.7691 - acc: 0.5332Epoch 1/10\n",
            "10/10 [==============================] - 172s 17s/step - loss: 0.7661 - acc: 0.5456 - val_loss: 0.6907 - val_acc: 0.5391\n",
            "Epoch 3/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.7413 - acc: 0.5538Epoch 1/10\n",
            "10/10 [==============================] - 172s 17s/step - loss: 0.7377 - acc: 0.5535 - val_loss: 0.6513 - val_acc: 0.6406\n",
            "Epoch 4/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6429 - acc: 0.6189Epoch 1/10\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.6484 - acc: 0.6164 - val_loss: 0.6220 - val_acc: 0.6719\n",
            "Epoch 5/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6491 - acc: 0.6198Epoch 1/10\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.6416 - acc: 0.6336 - val_loss: 0.5953 - val_acc: 0.7109\n",
            "Epoch 6/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6274 - acc: 0.6469Epoch 1/10\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.6283 - acc: 0.6494 - val_loss: 0.5711 - val_acc: 0.7578\n",
            "Epoch 7/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.5783 - acc: 0.6736Epoch 1/10\n",
            "10/10 [==============================] - 173s 17s/step - loss: 0.5828 - acc: 0.6609 - val_loss: 0.5509 - val_acc: 0.7500\n",
            "Epoch 8/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.5652 - acc: 0.6958Epoch 1/10\n",
            "10/10 [==============================] - 172s 17s/step - loss: 0.5664 - acc: 0.6950 - val_loss: 0.5319 - val_acc: 0.7500\n",
            "Epoch 9/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.5163 - acc: 0.7378Epoch 1/10\n",
            "10/10 [==============================] - 172s 17s/step - loss: 0.5199 - acc: 0.7343 - val_loss: 0.5142 - val_acc: 0.7969\n",
            "Epoch 10/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.5242 - acc: 0.7430Epoch 1/10\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.5272 - acc: 0.7389 - val_loss: 0.5002 - val_acc: 0.7891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc25af2a4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doc9og1dtSRp",
        "colab_type": "text"
      },
      "source": [
        "### Оценим качество сети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXvmyb4Csjwa",
        "colab_type": "code",
        "outputId": "34279419-6994-47d5-aad2-cedccca29104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Аккуратность на тестовых данных: 81.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4ddL6UctpPX",
        "colab_type": "text"
      },
      "source": [
        "### Применение метода Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fDPVYrztwFd",
        "colab_type": "text"
      },
      "source": [
        "\"Размораживаем\" последний сверточный блок сети VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwp6Z_nZtzP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_net.trainable = True\n",
        "trainable = False\n",
        "for layer in vgg16_net.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        trainable = True\n",
        "    layer.trainable = trainable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ix4pEQ2t8KE",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим на количество обучаемых параметров, оно должно было измениться."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3Za9hQ9xAyn",
        "colab_type": "code",
        "outputId": "df089d11-0c5c-46e4-b751-e9cd14d7b5f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "Total params: 9,732,929\n",
            "Trainable params: 2,097,665\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7NpYe7euD2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKg3y9gc34YX",
        "colab_type": "text"
      },
      "source": [
        "Возьмем небольшое количество эпох, чтобы избежать переобучения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79yXfK-3uHeg",
        "colab_type": "code",
        "outputId": "7a46ebe9-dc69-4aea-c88d-5591a24b3178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=2,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            " 9/10 [==========================>...] - ETA: 17s - loss: 0.4900 - acc: 0.7395Epoch 1/2\n",
            "10/10 [==============================] - 204s 20s/step - loss: 0.4853 - acc: 0.7469 - val_loss: 0.4455 - val_acc: 0.8203\n",
            "Epoch 2/2\n",
            " 9/10 [==========================>...] - ETA: 17s - loss: 0.3772 - acc: 0.8392Epoch 1/2\n",
            "10/10 [==============================] - 203s 20s/step - loss: 0.3854 - acc: 0.8286 - val_loss: 0.4063 - val_acc: 0.8047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc2573e1668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRbXQ4F0uKf1",
        "colab_type": "code",
        "outputId": "7f086a69-e902-4a74-81fc-d00a3582e2cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Аккуратность на тестовых данных: 85.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fRk2VpJzgYJ",
        "colab_type": "text"
      },
      "source": [
        "# VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cRk_Fw1zj2q",
        "colab_type": "text"
      },
      "source": [
        "Создадим собвтенную нейронную сеть на базе предобученной сети VGG16 (можно взять другую предобученную сеть по желанию, например, AlexNet, Interception и  т.д). \n",
        "\n",
        "Сравним полученные результаты и сделайте выводы.\n"
       
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hoz5GvIrwR0j",
        "colab_type": "text"
      },
      "source": [
        "нейронка с еще одним Dense после Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5-hFk3Pu9z7",
        "colab_type": "code",
        "outputId": "f4b7ec02-5552-49ff-fa35-f819856f6f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "vgg16_net1 = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "vgg16_net1.trainable = False\n",
        "x = vgg16_net1.output\n",
        "x = Flatten(name=\"flatten\")(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model1 = Model(inputs=vgg16_net1.input, outputs=predictions)\n",
        "model1.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model1.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "scores = model1.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.7030 - acc: 0.5350Epoch 1/10\n",
            "10/10 [==============================] - 170s 17s/step - loss: 0.7030 - acc: 0.5330 - val_loss: 0.6812 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6905 - acc: 0.5559Epoch 1/10\n",
            "10/10 [==============================] - 169s 17s/step - loss: 0.6873 - acc: 0.5660 - val_loss: 0.6682 - val_acc: 0.5312\n",
            "Epoch 3/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6574 - acc: 0.6364Epoch 1/10\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.6543 - acc: 0.6384 - val_loss: 0.6527 - val_acc: 0.6094\n",
            "Epoch 4/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6541 - acc: 0.6146Epoch 1/10\n",
            "10/10 [==============================] - 172s 17s/step - loss: 0.6527 - acc: 0.6187 - val_loss: 0.6392 - val_acc: 0.6406\n",
            "Epoch 5/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6501 - acc: 0.6276Epoch 1/10\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.6505 - acc: 0.6242 - val_loss: 0.6253 - val_acc: 0.6562\n",
            "Epoch 6/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6283 - acc: 0.6567Epoch 1/10\n",
            "10/10 [==============================] - 169s 17s/step - loss: 0.6248 - acc: 0.6646 - val_loss: 0.6119 - val_acc: 0.6875\n",
            "Epoch 7/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6082 - acc: 0.6667Epoch 1/10\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.6124 - acc: 0.6641 - val_loss: 0.5999 - val_acc: 0.7188\n",
            "Epoch 8/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.5993 - acc: 0.6871Epoch 1/10\n",
            "10/10 [==============================] - 170s 17s/step - loss: 0.6036 - acc: 0.6840 - val_loss: 0.5868 - val_acc: 0.7266\n",
            "Epoch 9/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.5704 - acc: 0.7394Epoch 1/10\n",
            "10/10 [==============================] - 170s 17s/step - loss: 0.5698 - acc: 0.7453 - val_loss: 0.5750 - val_acc: 0.7266\n",
            "Epoch 10/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.5579 - acc: 0.7726Epoch 1/10\n",
            "10/10 [==============================] - 172s 17s/step - loss: 0.5589 - acc: 0.7719 - val_loss: 0.5630 - val_acc: 0.7344\n",
            "Аккуратность на тестовых данных: 77.34%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuSqqMuzxfdF",
        "colab_type": "text"
      },
      "source": [
        "нейронка с Dropout с разным процентом исключения нейронов (увеличилось время работы)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fsjut2Tu9wh",
        "colab_type": "code",
        "outputId": "089ae123-0063-43bd-ed24-11ab0840945e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "vgg16_net2 = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "vgg16_net2.trainable = False\n",
        "x = vgg16_net2.output\n",
        "x = Flatten(name=\"flatten\")(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "x = Dropout(0.3)(x)\n",
        "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model2 = Model(inputs=vgg16_net2.input, outputs=predictions)\n",
        "model2.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "scores = model2.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.8128 - acc: 0.5192Epoch 1/10\n",
            "10/10 [==============================] - 172s 17s/step - loss: 0.8069 - acc: 0.5142 - val_loss: 0.6979 - val_acc: 0.5547\n",
            "Epoch 2/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.7030 - acc: 0.5399Epoch 1/10\n",
            "10/10 [==============================] - 172s 17s/step - loss: 0.7049 - acc: 0.5377 - val_loss: 0.6483 - val_acc: 0.6484\n",
            "Epoch 3/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6786 - acc: 0.5857Epoch 1/10\n",
            "10/10 [==============================] - 173s 17s/step - loss: 0.6756 - acc: 0.5896 - val_loss: 0.6117 - val_acc: 0.6875\n",
            "Epoch 4/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6203 - acc: 0.6434Epoch 1/10\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.6186 - acc: 0.6399 - val_loss: 0.5881 - val_acc: 0.7188\n",
            "Epoch 5/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6020 - acc: 0.6493Epoch 1/10\n",
            "10/10 [==============================] - 172s 17s/step - loss: 0.5988 - acc: 0.6516 - val_loss: 0.5584 - val_acc: 0.7578\n",
            "Epoch 6/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.5755 - acc: 0.6836Epoch 1/10\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.5712 - acc: 0.6887 - val_loss: 0.5298 - val_acc: 0.7969\n",
            "Epoch 7/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.5385 - acc: 0.7238Epoch 1/10\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.5369 - acc: 0.7264 - val_loss: 0.5089 - val_acc: 0.8047\n",
            "Epoch 8/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.5151 - acc: 0.7570Epoch 1/10\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.5155 - acc: 0.7563 - val_loss: 0.4885 - val_acc: 0.8047\n",
            "Epoch 9/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.5091 - acc: 0.7605Epoch 1/10\n",
            "10/10 [==============================] - 170s 17s/step - loss: 0.5108 - acc: 0.7563 - val_loss: 0.4743 - val_acc: 0.8203\n",
            "Epoch 10/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.4578 - acc: 0.7986Epoch 1/10\n",
            "10/10 [==============================] - 173s 17s/step - loss: 0.4580 - acc: 0.7969 - val_loss: 0.4610 - val_acc: 0.8281\n",
            "Аккуратность на тестовых данных: 82.81%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhf66Npdu9uX",
        "colab_type": "code",
        "outputId": "133a0735-b053-4b10-872b-da952151682d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "vgg16_net3 = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "vgg16_net3.trainable = False\n",
        "x = vgg16_net3.output\n",
        "x = Flatten(name=\"flatten\")(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "x = Dropout(0.7)(x)\n",
        "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model3 = Model(inputs=vgg16_net3.input, outputs=predictions)\n",
        "model3.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model3.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "scores = model3.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Epoch 1/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.8803 - acc: 0.4808Epoch 1/10\n",
            "10/10 [==============================] - 170s 17s/step - loss: 0.8733 - acc: 0.4874 - val_loss: 0.7131 - val_acc: 0.4922\n",
            "Epoch 2/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.8665 - acc: 0.4930Epoch 1/10\n",
            "10/10 [==============================] - 170s 17s/step - loss: 0.8591 - acc: 0.5031 - val_loss: 0.6757 - val_acc: 0.5859\n",
            "Epoch 3/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.8169 - acc: 0.5385Epoch 1/10\n",
            "10/10 [==============================] - 169s 17s/step - loss: 0.8090 - acc: 0.5409 - val_loss: 0.6470 - val_acc: 0.6797\n",
            "Epoch 4/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.7655 - acc: 0.5660Epoch 1/10\n",
            "10/10 [==============================] - 170s 17s/step - loss: 0.7637 - acc: 0.5656 - val_loss: 0.6251 - val_acc: 0.7188\n",
            "Epoch 5/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.7395 - acc: 0.5734Epoch 1/10\n",
            "10/10 [==============================] - 169s 17s/step - loss: 0.7230 - acc: 0.5802 - val_loss: 0.6052 - val_acc: 0.7578\n",
            "Epoch 6/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6772 - acc: 0.6074Epoch 1/10\n",
            "10/10 [==============================] - 168s 17s/step - loss: 0.6728 - acc: 0.6139 - val_loss: 0.5831 - val_acc: 0.7500\n",
            "Epoch 7/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6884 - acc: 0.6042Epoch 1/10\n",
            "10/10 [==============================] - 170s 17s/step - loss: 0.6784 - acc: 0.6125 - val_loss: 0.5636 - val_acc: 0.7344\n",
            "Epoch 8/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6324 - acc: 0.6294Epoch 1/10\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.6330 - acc: 0.6352 - val_loss: 0.5495 - val_acc: 0.7500\n",
            "Epoch 9/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6200 - acc: 0.6818Epoch 1/10\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.6051 - acc: 0.6918 - val_loss: 0.5375 - val_acc: 0.7734\n",
            "Epoch 10/10\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.5822 - acc: 0.6783Epoch 1/10\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.5910 - acc: 0.6714 - val_loss: 0.5232 - val_acc: 0.7656\n",
            "Аккуратность на тестовых данных: 85.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW39Z3W6yMh1",
        "colab_type": "text"
      },
      "source": [
        "нейронка с меньшим количеством эпох (2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7pyGtmSu9sL",
        "colab_type": "code",
        "outputId": "a08b1da0-3aa7-4729-800c-fc8e33a790bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "vgg16_net4 = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "vgg16_net4.trainable = False\n",
        "x = vgg16_net4.output\n",
        "x = Flatten(name=\"flatten\")(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model4 = Model(inputs=vgg16_net4.input, outputs=predictions)\n",
        "model4.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model4.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=2,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "scores = model4.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.7437 - acc: 0.5332Epoch 1/2\n",
            "10/10 [==============================] - 172s 17s/step - loss: 0.7520 - acc: 0.5220 - val_loss: 0.6938 - val_acc: 0.5781\n",
            "Epoch 2/2\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.7421 - acc: 0.5490Epoch 1/2\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.7370 - acc: 0.5503 - val_loss: 0.6550 - val_acc: 0.6172\n",
            "Аккуратность на тестовых данных: 59.38%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nUd8aq4y1bv",
        "colab_type": "text"
      },
      "source": [
        "нейронка с меньшим количеством эпох (5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohgdjA25u9pl",
        "colab_type": "code",
        "outputId": "6774eb78-eafb-4bb3-e257-577fb446528d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "vgg16_net5 = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "vgg16_net5.trainable = False\n",
        "x = vgg16_net5.output\n",
        "x = Flatten(name=\"flatten\")(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model5 = Model(inputs=vgg16_net5.input, outputs=predictions)\n",
        "model5.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model5.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=5,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "scores = model5.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.7536 - acc: 0.5262Epoch 1/5\n",
            "10/10 [==============================] - 172s 17s/step - loss: 0.7490 - acc: 0.5252 - val_loss: 0.6750 - val_acc: 0.5312\n",
            "Epoch 2/5\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6911 - acc: 0.5781Epoch 1/5\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.6880 - acc: 0.5818 - val_loss: 0.6413 - val_acc: 0.5859\n",
            "Epoch 3/5\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6838 - acc: 0.5927Epoch 1/5\n",
            "10/10 [==============================] - 172s 17s/step - loss: 0.6873 - acc: 0.5881 - val_loss: 0.6138 - val_acc: 0.6484\n",
            "Epoch 4/5\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6385 - acc: 0.6319Epoch 1/5\n",
            "10/10 [==============================] - 172s 17s/step - loss: 0.6359 - acc: 0.6313 - val_loss: 0.5909 - val_acc: 0.7031\n",
            "Epoch 5/5\n",
            " 9/10 [==========================>...] - ETA: 14s - loss: 0.6181 - acc: 0.6461Epoch 1/5\n",
            "10/10 [==============================] - 171s 17s/step - loss: 0.6109 - acc: 0.6646 - val_loss: 0.5686 - val_acc: 0.7031\n",
            "Аккуратность на тестовых данных: 80.47%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfH91vnovmab",
        "colab_type": "code",
        "outputId": "020cab8c-4904-4c60-df32-3c67252a13e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "vgg16_net6 = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "vgg16_net6.trainable = False\n",
        "x = vgg16_net6.output\n",
        "x = Flatten(name=\"flatten\")(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model6 = Model(inputs=vgg16_net6.input, outputs=predictions)\n",
        "model6.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model6.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=13,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "scores = model6.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/13\n",
            " 9/10 [==========================>...] - ETA: 13s - loss: 0.8602 - acc: 0.4931Epoch 1/13\n",
            "10/10 [==============================] - 166s 17s/step - loss: 0.8521 - acc: 0.4921 - val_loss: 0.7145 - val_acc: 0.5000\n",
            "Epoch 2/13\n",
            " 9/10 [==========================>...] - ETA: 13s - loss: 0.7747 - acc: 0.5000Epoch 1/13\n",
            "10/10 [==============================] - 166s 17s/step - loss: 0.7752 - acc: 0.5031 - val_loss: 0.6725 - val_acc: 0.5938\n",
            "Epoch 3/13\n",
            " 9/10 [==========================>...] - ETA: 13s - loss: 0.7606 - acc: 0.5295Epoch 1/13\n",
            "10/10 [==============================] - 166s 17s/step - loss: 0.7638 - acc: 0.5234 - val_loss: 0.6406 - val_acc: 0.6406\n",
            "Epoch 4/13\n",
            " 9/10 [==========================>...] - ETA: 13s - loss: 0.7500 - acc: 0.5559Epoch 1/13\n",
            "10/10 [==============================] - 165s 16s/step - loss: 0.7446 - acc: 0.5613 - val_loss: 0.6129 - val_acc: 0.6797\n",
            "Epoch 5/13\n",
            " 9/10 [==========================>...] - ETA: 13s - loss: 0.6561 - acc: 0.6144Epoch 1/13\n",
            "10/10 [==============================] - 163s 16s/step - loss: 0.6535 - acc: 0.6187 - val_loss: 0.5911 - val_acc: 0.6953\n",
            "Epoch 6/13\n",
            " 9/10 [==========================>...] - ETA: 13s - loss: 0.6474 - acc: 0.6354Epoch 1/13\n",
            "10/10 [==============================] - 165s 16s/step - loss: 0.6409 - acc: 0.6336 - val_loss: 0.5665 - val_acc: 0.6953\n",
            "Epoch 7/13\n",
            " 9/10 [==========================>...] - ETA: 13s - loss: 0.6221 - acc: 0.6562Epoch 1/13\n",
            "10/10 [==============================] - 166s 17s/step - loss: 0.6238 - acc: 0.6578 - val_loss: 0.5475 - val_acc: 0.7109\n",
            "Epoch 8/13\n",
            " 9/10 [==========================>...] - ETA: 13s - loss: 0.5544 - acc: 0.7010Epoch 1/13\n",
            "10/10 [==============================] - 164s 16s/step - loss: 0.5510 - acc: 0.7075 - val_loss: 0.5317 - val_acc: 0.7109\n",
            "Epoch 9/13\n",
            " 9/10 [==========================>...] - ETA: 13s - loss: 0.5796 - acc: 0.6958Epoch 1/13\n",
            "10/10 [==============================] - 166s 17s/step - loss: 0.5729 - acc: 0.7060 - val_loss: 0.5151 - val_acc: 0.7422\n",
            "Epoch 10/13\n",
            " 9/10 [==========================>...] - ETA: 13s - loss: 0.5215 - acc: 0.7325Epoch 1/13\n",
            "10/10 [==============================] - 165s 16s/step - loss: 0.5185 - acc: 0.7358 - val_loss: 0.5011 - val_acc: 0.7500\n",
            "Epoch 11/13\n",
            " 9/10 [==========================>...] - ETA: 13s - loss: 0.5044 - acc: 0.7622Epoch 1/13\n",
            "10/10 [==============================] - 165s 16s/step - loss: 0.5010 - acc: 0.7689 - val_loss: 0.4886 - val_acc: 0.7734\n",
            "Epoch 12/13\n",
            " 9/10 [==========================>...] - ETA: 13s - loss: 0.4999 - acc: 0.7674Epoch 1/13\n",
            "10/10 [==============================] - 164s 16s/step - loss: 0.5073 - acc: 0.7626 - val_loss: 0.4742 - val_acc: 0.7734\n",
            "Epoch 13/13\n",
            " 9/10 [==========================>...] - ETA: 13s - loss: 0.4758 - acc: 0.7867Epoch 1/13\n",
            "10/10 [==============================] - 166s 17s/step - loss: 0.4741 - acc: 0.7893 - val_loss: 0.4660 - val_acc: 0.7969\n",
            "Аккуратность на тестовых данных: 84.38%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
